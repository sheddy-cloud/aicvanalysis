{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gensim\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on Lemmatized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moment      sportscenter play      pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>m find lack post alarming Sex boring s posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good             course   know   s blessing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>Dear INTP     enjoy conversation day    esot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire s silly misconception   approach logica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>think cat Fi dom reason       website have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread exist someplace        heck delete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>question thing    purple pill   pick win lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right come want child    honestly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long personalitycafe    doesn t change bit  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ      intj moment      sportscenter play      pr...\n",
       "1     ENTP    m find lack post alarming Sex boring s posit...\n",
       "2     INTP    good             course   know   s blessing ...\n",
       "3     INTJ    Dear INTP     enjoy conversation day    esot...\n",
       "4     ENTJ    fire s silly misconception   approach logica...\n",
       "...    ...                                                ...\n",
       "8670  ISFP      think cat Fi dom reason       website have...\n",
       "8671  ENFP       thread exist someplace        heck delete...\n",
       "8672  INTP    question thing    purple pill   pick win lot...\n",
       "8673  INFP    conflicted right come want child    honestly...\n",
       "8674  INFP    long personalitycafe    doesn t change bit  ...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/preprocessed/mbti_lemmatized.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = gensim.models.Word2Vec.load('../models/gensim_wikipedia_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_test_evaluate_report(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Trains, tests, and evaluates a model using Word2Vec document vectors with MinMax scaling.\n",
    "\n",
    "    Args:\n",
    "        model: The scikit-learn classifier model.\n",
    "        X_train: Training posts (pandas Series).\n",
    "        X_test: Testing posts (pandas Series).\n",
    "        y_train: Training labels (pandas Series).\n",
    "        y_test: Testing labels (pandas Series).\n",
    "        vectorizer: The pre-loaded Word2Vec model.\n",
    "    \"\"\"\n",
    "\n",
    "    def preprocess_posts(posts):\n",
    "        processed_posts = []\n",
    "        for post in posts:\n",
    "            if isinstance(post, str):\n",
    "                words = post.lower().split()\n",
    "                cleaned_words = [word for word in words if word.isalnum() and len(word) > 2]\n",
    "                processed_posts.append(cleaned_words)\n",
    "            else:\n",
    "                processed_posts.append([])\n",
    "        return processed_posts\n",
    "\n",
    "    def document_vector(words, model):\n",
    "        words = [word for word in words if word in model.wv]\n",
    "        if len(words) == 0:\n",
    "            return np.zeros(model.vector_size)\n",
    "        return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "    # Preprocess posts\n",
    "    X_train_processed = preprocess_posts(X_train)\n",
    "    X_test_processed = preprocess_posts(X_test)\n",
    "\n",
    "    # Create document vectors by iterating over the processed data\n",
    "    X_train_vec = np.vstack([document_vector(post, vectorizer) for post in X_train_processed])\n",
    "    X_test_vec = np.vstack([document_vector(post, vectorizer) for post in X_test_processed])\n",
    "\n",
    "    # Apply MinMax scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_vec_scaled = scaler.fit_transform(X_train_vec)\n",
    "    X_test_vec_scaled = scaler.transform(X_test_vec)\n",
    "\n",
    "    # Encode target labels\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_vec_scaled, y_train_encoded)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test_encoded, model.predict(X_test_vec_scaled),\n",
    "                                    target_names=encoder.inverse_transform([i for i in range(16)]),\n",
    "                                    output_dict=True)\n",
    "\n",
    "    # Extract metrics\n",
    "    accuracy = report['accuracy']\n",
    "    macro_precision = report['macro avg']['precision']\n",
    "    weighted_recall = report['weighted avg']['recall']\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Macro Precision: {macro_precision}\")\n",
    "    print(f\"Weighted Recall: {weighted_recall} \\n\\n\")\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28472622478386167\n",
      "Macro Precision: 0.1238409506203725\n",
      "Weighted Recall: 0.28472622478386167 \n",
      "\n",
      "\n",
      "Accuracy: 0.30662824207492795\n",
      "Macro Precision: 0.12161534787060867\n",
      "Weighted Recall: 0.30662824207492795 \n",
      "\n",
      "\n",
      "Accuracy: 0.30144092219020174\n",
      "Macro Precision: 0.15579094801866056\n",
      "Weighted Recall: 0.30144092219020174 \n",
      "\n",
      "\n",
      "Accuracy: 0.29394812680115273\n",
      "Macro Precision: 0.17731062961707922\n",
      "Weighted Recall: 0.29394812680115273 \n",
      "\n",
      "\n",
      "Accuracy: 0.29913544668587894\n",
      "Macro Precision: 0.12300055744166069\n",
      "Weighted Recall: 0.29913544668587894 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index] \\\n",
    "        , df.type[train_index], df.type[test_index]\n",
    "    model = LogisticRegression()\n",
    "    score.append(train_test_evaluate_report(model,X_train, X_test, y_train, y_test))\n",
    "    \n",
    "summary = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16772334293948127\n",
      "Macro Precision: 0.07810691783053253\n",
      "Weighted Recall: 0.16772334293948127 \n",
      "\n",
      "\n",
      "Accuracy: 0.1585014409221902\n",
      "Macro Precision: 0.07982906321645182\n",
      "Weighted Recall: 0.1585014409221902 \n",
      "\n",
      "\n",
      "Accuracy: 0.15965417867435158\n",
      "Macro Precision: 0.07912867029202571\n",
      "Weighted Recall: 0.15965417867435158 \n",
      "\n",
      "\n",
      "Accuracy: 0.1786743515850144\n",
      "Macro Precision: 0.08475993594000553\n",
      "Weighted Recall: 0.1786743515850144 \n",
      "\n",
      "\n",
      "Accuracy: 0.14755043227665707\n",
      "Macro Precision: 0.06815048680559123\n",
      "Weighted Recall: 0.14755043227665707 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts.iloc[train_index], df.posts.iloc[test_index], df.type.iloc[train_index], df.type.iloc[test_index]\n",
    "    model = DecisionTreeClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "summary = {\n",
    "    \"model\": \"DecisionTreeClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21498559077809798\n",
      "Macro Precision: 0.03506418884599756\n",
      "Weighted Recall: 0.21498559077809798 \n",
      "\n",
      "\n",
      "Accuracy: 0.21268011527377523\n",
      "Macro Precision: 0.028895796974985455\n",
      "Weighted Recall: 0.21268011527377523 \n",
      "\n",
      "\n",
      "Accuracy: 0.21440922190201728\n",
      "Macro Precision: 0.02727911843568112\n",
      "Weighted Recall: 0.21440922190201728 \n",
      "\n",
      "\n",
      "Accuracy: 0.21268011527377523\n",
      "Macro Precision: 0.02799213744903902\n",
      "Weighted Recall: 0.21268011527377523 \n",
      "\n",
      "\n",
      "Accuracy: 0.21210374639769453\n",
      "Macro Precision: 0.028870512449334106\n",
      "Weighted Recall: 0.21210374639769453 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts.iloc[train_index], df.posts.iloc[test_index], df.type.iloc[train_index], df.type.iloc[test_index]\n",
    "    model = MultinomialNB()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "summary = {\n",
    "    \"model\": \"MultinomialNB\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2680115273775216\n",
      "Macro Precision: 0.1349460807424873\n",
      "Weighted Recall: 0.2680115273775216 \n",
      "\n",
      "\n",
      "Accuracy: 0.28357348703170027\n",
      "Macro Precision: 0.1152683119651642\n",
      "Weighted Recall: 0.28357348703170027 \n",
      "\n",
      "\n",
      "Accuracy: 0.2760806916426513\n",
      "Macro Precision: 0.11666198959947047\n",
      "Weighted Recall: 0.2760806916426513 \n",
      "\n",
      "\n",
      "Accuracy: 0.2680115273775216\n",
      "Macro Precision: 0.18315088831982884\n",
      "Weighted Recall: 0.2680115273775216 \n",
      "\n",
      "\n",
      "Accuracy: 0.2703170028818444\n",
      "Macro Precision: 0.24603565036887964\n",
      "Weighted Recall: 0.2703170028818444 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = HistGradientBoostingClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"HistGradientBoostingClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2922190201729107\n",
      "Macro Precision: 0.10981045680618029\n",
      "Weighted Recall: 0.2922190201729107 \n",
      "\n",
      "\n",
      "Accuracy: 0.3048991354466859\n",
      "Macro Precision: 0.1257834307647264\n",
      "Weighted Recall: 0.3048991354466859 \n",
      "\n",
      "\n",
      "Accuracy: 0.2985590778097983\n",
      "Macro Precision: 0.14882991898145748\n",
      "Weighted Recall: 0.2985590778097983 \n",
      "\n",
      "\n",
      "Accuracy: 0.30086455331412104\n",
      "Macro Precision: 0.18384420435964002\n",
      "Weighted Recall: 0.30086455331412104 \n",
      "\n",
      "\n",
      "Accuracy: 0.2864553314121037\n",
      "Macro Precision: 0.12499950980467175\n",
      "Weighted Recall: 0.2864553314121037 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = SVC()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"SVC\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26455331412103744\n",
      "Macro Precision: 0.14124329357082904\n",
      "Weighted Recall: 0.26455331412103744 \n",
      "\n",
      "\n",
      "Accuracy: 0.2760806916426513\n",
      "Macro Precision: 0.10703597696349106\n",
      "Weighted Recall: 0.2760806916426513 \n",
      "\n",
      "\n",
      "Accuracy: 0.27204610951008645\n",
      "Macro Precision: 0.1383653578443373\n",
      "Weighted Recall: 0.27204610951008645 \n",
      "\n",
      "\n",
      "Accuracy: 0.2703170028818444\n",
      "Macro Precision: 0.12271738758764089\n",
      "Weighted Recall: 0.2703170028818444 \n",
      "\n",
      "\n",
      "Accuracy: 0.2703170028818444\n",
      "Macro Precision: 0.12113559912017666\n",
      "Weighted Recall: 0.2703170028818444 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"RandomForestClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25936599423631124\n",
      "Macro Precision: 0.10260590216334965\n",
      "Weighted Recall: 0.25936599423631124 \n",
      "\n",
      "\n",
      "Accuracy: 0.269164265129683\n",
      "Macro Precision: 0.08674481525488803\n",
      "Weighted Recall: 0.269164265129683 \n",
      "\n",
      "\n",
      "Accuracy: 0.2564841498559078\n",
      "Macro Precision: 0.09064013335954825\n",
      "Weighted Recall: 0.2564841498559078 \n",
      "\n",
      "\n",
      "Accuracy: 0.25936599423631124\n",
      "Macro Precision: 0.10709121718375542\n",
      "Weighted Recall: 0.25936599423631124 \n",
      "\n",
      "\n",
      "Accuracy: 0.26570605187319885\n",
      "Macro Precision: 0.1052347387889993\n",
      "Weighted Recall: 0.26570605187319885 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=9, warm_start=True)\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"GradientBoostingClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"yes\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on Unlemmatized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moment      sportscenter play      pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>m find lack post alarming Sex boring s posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good             course   know   s blessing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>Dear INTP     enjoy conversation day    esot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire s silly misconception   approach logica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>think cat Fi dom reason       website have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread exist someplace        heck delete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>question thing    purple pill   pick win lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right come want child    honestly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long personalitycafe    doesn t change bit  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ      intj moment      sportscenter play      pr...\n",
       "1     ENTP    m find lack post alarming Sex boring s posit...\n",
       "2     INTP    good             course   know   s blessing ...\n",
       "3     INTJ    Dear INTP     enjoy conversation day    esot...\n",
       "4     ENTJ    fire s silly misconception   approach logica...\n",
       "...    ...                                                ...\n",
       "8670  ISFP      think cat Fi dom reason       website have...\n",
       "8671  ENFP       thread exist someplace        heck delete...\n",
       "8672  INTP    question thing    purple pill   pick win lot...\n",
       "8673  INFP    conflicted right come want child    honestly...\n",
       "8674  INFP    long personalitycafe    doesn t change bit  ...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/preprocessed/mbti_lemmatized.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28472622478386167\n",
      "Macro Precision: 0.1238409506203725\n",
      "Weighted Recall: 0.28472622478386167 \n",
      "\n",
      "\n",
      "Accuracy: 0.30662824207492795\n",
      "Macro Precision: 0.12161534787060867\n",
      "Weighted Recall: 0.30662824207492795 \n",
      "\n",
      "\n",
      "Accuracy: 0.30144092219020174\n",
      "Macro Precision: 0.15579094801866056\n",
      "Weighted Recall: 0.30144092219020174 \n",
      "\n",
      "\n",
      "Accuracy: 0.29394812680115273\n",
      "Macro Precision: 0.17731062961707922\n",
      "Weighted Recall: 0.29394812680115273 \n",
      "\n",
      "\n",
      "Accuracy: 0.29913544668587894\n",
      "Macro Precision: 0.12300055744166069\n",
      "Weighted Recall: 0.29913544668587894 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index] \\\n",
    "        , df.type[train_index], df.type[test_index]\n",
    "    model = LogisticRegression()\n",
    "    score.append(train_test_evaluate_report(model,X_train, X_test, y_train, y_test))\n",
    "    \n",
    "summary = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17636887608069166\n",
      "Macro Precision: 0.08925435261875488\n",
      "Weighted Recall: 0.17636887608069166 \n",
      "\n",
      "\n",
      "Accuracy: 0.16368876080691644\n",
      "Macro Precision: 0.08142790119141838\n",
      "Weighted Recall: 0.16368876080691644 \n",
      "\n",
      "\n",
      "Accuracy: 0.1579250720461095\n",
      "Macro Precision: 0.07579825469214853\n",
      "Weighted Recall: 0.1579250720461095 \n",
      "\n",
      "\n",
      "Accuracy: 0.16138328530259366\n",
      "Macro Precision: 0.07762651269705402\n",
      "Weighted Recall: 0.16138328530259366 \n",
      "\n",
      "\n",
      "Accuracy: 0.14927953890489915\n",
      "Macro Precision: 0.0702268316406635\n",
      "Weighted Recall: 0.14927953890489915 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts.iloc[train_index], df.posts.iloc[test_index], df.type.iloc[train_index], df.type.iloc[test_index]\n",
    "    model = DecisionTreeClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "summary = {\n",
    "    \"model\": \"DecisionTreeClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21498559077809798\n",
      "Macro Precision: 0.03506418884599756\n",
      "Weighted Recall: 0.21498559077809798 \n",
      "\n",
      "\n",
      "Accuracy: 0.21268011527377523\n",
      "Macro Precision: 0.028895796974985455\n",
      "Weighted Recall: 0.21268011527377523 \n",
      "\n",
      "\n",
      "Accuracy: 0.21440922190201728\n",
      "Macro Precision: 0.02727911843568112\n",
      "Weighted Recall: 0.21440922190201728 \n",
      "\n",
      "\n",
      "Accuracy: 0.21268011527377523\n",
      "Macro Precision: 0.02799213744903902\n",
      "Weighted Recall: 0.21268011527377523 \n",
      "\n",
      "\n",
      "Accuracy: 0.21210374639769453\n",
      "Macro Precision: 0.028870512449334106\n",
      "Weighted Recall: 0.21210374639769453 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n",
      "23                   MultinomialNB            Word2Vec         no  0.213372\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "report = pd.read_csv('./report.csv')\n",
    "score = []\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts.iloc[train_index], df.posts.iloc[test_index], df.type.iloc[train_index], df.type.iloc[test_index]\n",
    "    model = MultinomialNB()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "summary = {\n",
    "    \"model\": \"MultinomialNB\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Based Gradiant Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2680115273775216\n",
      "Macro Precision: 0.1349460807424873\n",
      "Weighted Recall: 0.2680115273775216 \n",
      "\n",
      "\n",
      "Accuracy: 0.28357348703170027\n",
      "Macro Precision: 0.1152683119651642\n",
      "Weighted Recall: 0.28357348703170027 \n",
      "\n",
      "\n",
      "Accuracy: 0.2760806916426513\n",
      "Macro Precision: 0.11666198959947047\n",
      "Weighted Recall: 0.2760806916426513 \n",
      "\n",
      "\n",
      "Accuracy: 0.2680115273775216\n",
      "Macro Precision: 0.18315088831982884\n",
      "Weighted Recall: 0.2680115273775216 \n",
      "\n",
      "\n",
      "Accuracy: 0.2703170028818444\n",
      "Macro Precision: 0.24603565036887964\n",
      "Weighted Recall: 0.2703170028818444 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n",
      "23                   MultinomialNB            Word2Vec         no  0.213372\n",
      "24  HistGradientBoostingClassifier            Word2Vec         no  0.273199\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = HistGradientBoostingClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"HistGradientBoostingClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2922190201729107\n",
      "Macro Precision: 0.10981045680618029\n",
      "Weighted Recall: 0.2922190201729107 \n",
      "\n",
      "\n",
      "Accuracy: 0.3048991354466859\n",
      "Macro Precision: 0.1257834307647264\n",
      "Weighted Recall: 0.3048991354466859 \n",
      "\n",
      "\n",
      "Accuracy: 0.2985590778097983\n",
      "Macro Precision: 0.14882991898145748\n",
      "Weighted Recall: 0.2985590778097983 \n",
      "\n",
      "\n",
      "Accuracy: 0.30086455331412104\n",
      "Macro Precision: 0.18384420435964002\n",
      "Weighted Recall: 0.30086455331412104 \n",
      "\n",
      "\n",
      "Accuracy: 0.2864553314121037\n",
      "Macro Precision: 0.12499950980467175\n",
      "Weighted Recall: 0.2864553314121037 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n",
      "23                   MultinomialNB            Word2Vec         no  0.213372\n",
      "24  HistGradientBoostingClassifier            Word2Vec         no  0.273199\n",
      "25                             SVC            Word2Vec         no  0.296599\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = SVC()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"SVC\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2760806916426513\n",
      "Macro Precision: 0.1309992570012704\n",
      "Weighted Recall: 0.2760806916426513 \n",
      "\n",
      "\n",
      "Accuracy: 0.2824207492795389\n",
      "Macro Precision: 0.11593110299802799\n",
      "Weighted Recall: 0.2824207492795389 \n",
      "\n",
      "\n",
      "Accuracy: 0.2639769452449568\n",
      "Macro Precision: 0.10045831257253829\n",
      "Weighted Recall: 0.2639769452449568 \n",
      "\n",
      "\n",
      "Accuracy: 0.2610951008645533\n",
      "Macro Precision: 0.1260772658675006\n",
      "Weighted Recall: 0.2610951008645533 \n",
      "\n",
      "\n",
      "Accuracy: 0.26512968299711814\n",
      "Macro Precision: 0.09315346787184467\n",
      "Weighted Recall: 0.26512968299711814 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n",
      "23                   MultinomialNB            Word2Vec         no  0.213372\n",
      "24  HistGradientBoostingClassifier            Word2Vec         no  0.273199\n",
      "25                             SVC            Word2Vec         no  0.296599\n",
      "26          RandomForestClassifier            Word2Vec         no  0.269741\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"RandomForestClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26051873198847264\n",
      "Macro Precision: 0.10705207040681744\n",
      "Weighted Recall: 0.26051873198847264 \n",
      "\n",
      "\n",
      "Accuracy: 0.2564841498559078\n",
      "Macro Precision: 0.08693031999713283\n",
      "Weighted Recall: 0.2564841498559078 \n",
      "\n",
      "\n",
      "Accuracy: 0.2570605187319885\n",
      "Macro Precision: 0.10517443152709255\n",
      "Weighted Recall: 0.2570605187319885 \n",
      "\n",
      "\n",
      "Accuracy: 0.2610951008645533\n",
      "Macro Precision: 0.1346911409724959\n",
      "Weighted Recall: 0.2610951008645533 \n",
      "\n",
      "\n",
      "Accuracy: 0.26570605187319885\n",
      "Macro Precision: 0.1161032210155017\n",
      "Weighted Recall: 0.26570605187319885 \n",
      "\n",
      "\n",
      "                             model text_representation lemmatized  accuracy\n",
      "0               LogisticRegression              TF-IDF        yes  0.659366\n",
      "1           DecisionTreeClassifier              TF-IDF        yes  0.489568\n",
      "2                    MultinomialNB              TF-IDF        yes  0.366455\n",
      "3   HistGradientBoostingClassifier              TF-IDF        yes  0.151931\n",
      "4                              SVC              TF-IDF        yes  0.654409\n",
      "5           RandomForestClassifier              TF-IDF        yes  0.521499\n",
      "6       GradientBoostingClassifier              TF-IDF        yes  0.611412\n",
      "7               LogisticRegression              TF-IDF         no  0.659366\n",
      "8           DecisionTreeClassifier              TF-IDF         no  0.490144\n",
      "9                    MultinomialNB              TF-IDF         no  0.366455\n",
      "10  HistGradientBoostingClassifier              TF-IDF         no  0.151931\n",
      "11                             SVC              TF-IDF         no  0.654409\n",
      "12          RandomForestClassifier              TF-IDF         no  0.522767\n",
      "13      GradientBoostingClassifier              TF-IDF         no  0.613948\n",
      "14              LogisticRegression            Word2Vec        yes  0.297176\n",
      "15          DecisionTreeClassifier            Word2Vec        yes  0.162421\n",
      "16                   MultinomialNB            Word2Vec        yes  0.213372\n",
      "17  HistGradientBoostingClassifier            Word2Vec        yes  0.273199\n",
      "18                             SVC            Word2Vec        yes  0.296599\n",
      "19          RandomForestClassifier            Word2Vec        yes  0.270663\n",
      "20      GradientBoostingClassifier            Word2Vec        yes  0.262017\n",
      "21              LogisticRegression            Word2Vec         no  0.297176\n",
      "22          DecisionTreeClassifier            Word2Vec         no  0.161729\n",
      "23                   MultinomialNB            Word2Vec         no  0.213372\n",
      "24  HistGradientBoostingClassifier            Word2Vec         no  0.273199\n",
      "25                             SVC            Word2Vec         no  0.296599\n",
      "26          RandomForestClassifier            Word2Vec         no  0.269741\n",
      "27      GradientBoostingClassifier            Word2Vec         no  0.260173\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "report = pd.read_csv('./report.csv')\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_index, test_index in folds.split(X=df.posts, y=df.type):\n",
    "    X_train, X_test, y_train, y_test = df.posts[train_index], df.posts[test_index], df.type[train_index], df.type[test_index]\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=9, warm_start=True)\n",
    "    score.append(train_test_evaluate_report(model, X_train, X_test, y_train, y_test))\n",
    "\n",
    "summary = {\n",
    "    \"model\": \"GradientBoostingClassifier\",\n",
    "    \"text_representation\": \"Word2Vec\",\n",
    "    \"lemmatized\": \"no\",\n",
    "    \"accuracy\": sum(score) / len(score)\n",
    "}\n",
    "\n",
    "report.loc[len(report)] = summary\n",
    "report.to_csv('./report.csv', index=False, header=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
