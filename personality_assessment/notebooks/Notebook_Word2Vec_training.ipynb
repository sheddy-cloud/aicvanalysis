{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Word Embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word corpus from twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'  and intj moments     sportscenter not top t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____     course, to which I say I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'  just because I always think of cats as Fi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  '  and intj moments     sportscenter not top t...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____     course, to which I say I ...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  '  just because I always think of cats as Fi d...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../dataset/preprocessed/mbti_no_urls.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>julie81</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>richardhester</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williamsjoseph</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>danielsmary</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>carlwarren</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>ntate</td>\n",
       "      <td>Agree reflect military box ability ever hold. ...</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-01-15 11:46:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>garrisonjoshua</td>\n",
       "      <td>Born which push still. Degree sometimes contro...</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>2023-05-06 00:46:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>adriennejackson</td>\n",
       "      <td>You day agent likely region. Teacher data mess...</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>2023-02-27 14:55:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>kcarlson</td>\n",
       "      <td>Guess without successful save. Particular natu...</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>2023-01-09 16:09:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>vdickerson</td>\n",
       "      <td>Body onto understand team about product beauti...</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>2023-04-19 01:35:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tweet_ID         Username  \\\n",
       "0            1          julie81   \n",
       "1            2    richardhester   \n",
       "2            3   williamsjoseph   \n",
       "3            4      danielsmary   \n",
       "4            5       carlwarren   \n",
       "...        ...              ...   \n",
       "9995      9996            ntate   \n",
       "9996      9997   garrisonjoshua   \n",
       "9997      9998  adriennejackson   \n",
       "9998      9999         kcarlson   \n",
       "9999     10000       vdickerson   \n",
       "\n",
       "                                                   Text  Retweets  Likes  \\\n",
       "0     Party least receive say or single. Prevent pre...         2     25   \n",
       "1     Hotel still Congress may member staff. Media d...        35     29   \n",
       "2     Nice be her debate industry that year. Film wh...        51     25   \n",
       "3     Laugh explain situation career occur serious. ...        37     18   \n",
       "4     Involve sense former often approach government...        27     80   \n",
       "...                                                 ...       ...    ...   \n",
       "9995  Agree reflect military box ability ever hold. ...        81     86   \n",
       "9996  Born which push still. Degree sometimes contro...        73    100   \n",
       "9997  You day agent likely region. Teacher data mess...        10     62   \n",
       "9998  Guess without successful save. Particular natu...        21     60   \n",
       "9999  Body onto understand team about product beauti...        65     54   \n",
       "\n",
       "                Timestamp  \n",
       "0     2023-01-30 11:00:51  \n",
       "1     2023-01-02 22:45:58  \n",
       "2     2023-01-18 11:25:19  \n",
       "3     2023-04-10 22:06:29  \n",
       "4     2023-01-24 07:12:21  \n",
       "...                   ...  \n",
       "9995  2023-01-15 11:46:20  \n",
       "9996  2023-05-06 00:46:54  \n",
       "9997  2023-02-27 14:55:08  \n",
       "9998  2023-01-09 16:09:35  \n",
       "9999  2023-04-19 01:35:56  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('../dataset/twitter_dataset.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename columns and merge to get one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>posts</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>julie81</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>richardhester</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williamsjoseph</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>danielsmary</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>carlwarren</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>ntate</td>\n",
       "      <td>Agree reflect military box ability ever hold. ...</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-01-15 11:46:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>garrisonjoshua</td>\n",
       "      <td>Born which push still. Degree sometimes contro...</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>2023-05-06 00:46:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>adriennejackson</td>\n",
       "      <td>You day agent likely region. Teacher data mess...</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>2023-02-27 14:55:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>kcarlson</td>\n",
       "      <td>Guess without successful save. Particular natu...</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>2023-01-09 16:09:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>vdickerson</td>\n",
       "      <td>Body onto understand team about product beauti...</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>2023-04-19 01:35:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tweet_ID         Username  \\\n",
       "0            1          julie81   \n",
       "1            2    richardhester   \n",
       "2            3   williamsjoseph   \n",
       "3            4      danielsmary   \n",
       "4            5       carlwarren   \n",
       "...        ...              ...   \n",
       "9995      9996            ntate   \n",
       "9996      9997   garrisonjoshua   \n",
       "9997      9998  adriennejackson   \n",
       "9998      9999         kcarlson   \n",
       "9999     10000       vdickerson   \n",
       "\n",
       "                                                  posts  Retweets  Likes  \\\n",
       "0     Party least receive say or single. Prevent pre...         2     25   \n",
       "1     Hotel still Congress may member staff. Media d...        35     29   \n",
       "2     Nice be her debate industry that year. Film wh...        51     25   \n",
       "3     Laugh explain situation career occur serious. ...        37     18   \n",
       "4     Involve sense former often approach government...        27     80   \n",
       "...                                                 ...       ...    ...   \n",
       "9995  Agree reflect military box ability ever hold. ...        81     86   \n",
       "9996  Born which push still. Degree sometimes contro...        73    100   \n",
       "9997  You day agent likely region. Teacher data mess...        10     62   \n",
       "9998  Guess without successful save. Particular natu...        21     60   \n",
       "9999  Body onto understand team about product beauti...        65     54   \n",
       "\n",
       "                Timestamp  \n",
       "0     2023-01-30 11:00:51  \n",
       "1     2023-01-02 22:45:58  \n",
       "2     2023-01-18 11:25:19  \n",
       "3     2023-04-10 22:06:29  \n",
       "4     2023-01-24 07:12:21  \n",
       "...                   ...  \n",
       "9995  2023-01-15 11:46:20  \n",
       "9996  2023-05-06 00:46:54  \n",
       "9997  2023-02-27 14:55:08  \n",
       "9998  2023-01-09 16:09:35  \n",
       "9999  2023-04-19 01:35:56  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_renamed = df2.rename(columns={\"Text\":\"posts\"})\n",
    "df2_renamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'  and intj moments     sportscenter not top t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one  _____     course, to which I say I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Agree reflect military box ability ever hold. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Born which push still. Degree sometimes contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You day agent likely region. Teacher data mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Guess without successful save. Particular natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Body onto understand team about product beauti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18675 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts\n",
       "0     '  and intj moments     sportscenter not top t...\n",
       "1     'I'm finding the lack of me in these posts ver...\n",
       "2     'Good one  _____     course, to which I say I ...\n",
       "3     'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     'You're fired.|||That's another silly misconce...\n",
       "...                                                 ...\n",
       "9995  Agree reflect military box ability ever hold. ...\n",
       "9996  Born which push still. Degree sometimes contro...\n",
       "9997  You day agent likely region. Teacher data mess...\n",
       "9998  Guess without successful save. Particular natu...\n",
       "9999  Body onto understand team about product beauti...\n",
       "\n",
       "[18675 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpous = pd.concat([df1['posts'], df2_renamed['posts']]).to_frame(name='posts')\n",
    "df_corpous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove pipe character from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'  and intj moments     sportscenter not top t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one  _____     course, to which I say I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired.That's another silly misconcepti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Agree reflect military box ability ever hold. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Born which push still. Degree sometimes contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You day agent likely region. Teacher data mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Guess without successful save. Particular natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Body onto understand team about product beauti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18675 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts\n",
       "0     '  and intj moments     sportscenter not top t...\n",
       "1     'I'm finding the lack of me in these posts ver...\n",
       "2     'Good one  _____     course, to which I say I ...\n",
       "3     'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     'You're fired.That's another silly misconcepti...\n",
       "...                                                 ...\n",
       "9995  Agree reflect military box ability ever hold. ...\n",
       "9996  Born which push still. Degree sometimes contro...\n",
       "9997  You day agent likely region. Teacher data mess...\n",
       "9998  Guess without successful save. Particular natu...\n",
       "9999  Body onto understand team about product beauti...\n",
       "\n",
       "[18675 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpous['posts'] = df_corpous['posts'].apply(lambda x: re.sub(\"\\|\", \"\", x))\n",
    "df_corpous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the corpus, remove stop words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [and, intj, moments, sportscenter, not, top, t...\n",
       "1       [finding, the, lack, of, me, in, these, posts,...\n",
       "2       [good, one, course, to, which, say, know, that...\n",
       "3       [dear, intp, enjoyed, our, conversation, the, ...\n",
       "4       [you, re, fired, that, another, silly, misconc...\n",
       "                              ...                        \n",
       "9995    [agree, reflect, military, box, ability, ever,...\n",
       "9996    [born, which, push, still, degree, sometimes, ...\n",
       "9997    [you, day, agent, likely, region, teacher, dat...\n",
       "9998    [guess, without, successful, save, particular,...\n",
       "9999    [body, onto, understand, team, about, product,...\n",
       "Name: posts, Length: 18675, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df_corpous['posts'].apply(gensim.utils.simple_preprocess)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(corpus, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40266488, 52050170)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/gensim_twitter_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cute', 0.7679351568222046),\n",
       " ('adorable', 0.764094889163971),\n",
       " ('awww', 0.7470967769622803),\n",
       " ('gorgeous', 0.7405201196670532),\n",
       " ('sexy', 0.7027244567871094),\n",
       " ('aww', 0.687999427318573),\n",
       " ('cuddly', 0.6878390908241272),\n",
       " ('fluffy', 0.6822195649147034),\n",
       " ('lovely', 0.6744773387908936),\n",
       " ('aw', 0.6539250016212463)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"sweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of: king - man + woman\n",
      "anne\n",
      "gables\n",
      "actress\n",
      "anneli\n",
      "elizabeth\n",
      "emily\n",
      "jane\n",
      "princess\n",
      "woman\n",
      "bennet\n"
     ]
    }
   ],
   "source": [
    "similar_vec = model.wv['king'] - model.wv['man'] + model.wv['woman']\n",
    "\n",
    "print(\"The result of: king - man + woman\")\n",
    "for result in model.wv.most_similar(positive=[similar_vec]):\n",
    "    print(result[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'April', '', 'April (Apr.) is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May. It is one of four months to have 30 days.', '']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "with open('../dataset/wikipedia.txt', 'r') as file:\n",
    "    sentences = [line.strip() for line in file]\n",
    "    print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [gensim.utils.simple_preprocess(sentence) for sentence in sentences]\n",
    "print(tokenized_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build_vocab(tokenized_corpus, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107527243, 139687095)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(tokenized_corpus, total_examples=model2.corpus_count, epochs=model2.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of: king - man + woman\n",
      "queen\n",
      "king\n",
      "princess\n",
      "throne\n",
      "consort\n",
      "prince\n",
      "monarch\n",
      "empress\n",
      "crown\n",
      "heir\n"
     ]
    }
   ],
   "source": [
    "similar_vec = model2.wv['king'] - model2.wv['man'] + model2.wv['woman']\n",
    "\n",
    "print(\"The result of: king - man + woman\")\n",
    "for result in model2.wv.most_similar(positive=[similar_vec]):\n",
    "    print(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lemon', 0.8211219310760498),\n",
       " ('juice', 0.8011748790740967),\n",
       " ('sour', 0.7980005145072937),\n",
       " ('pineapple', 0.7959660291671753),\n",
       " ('potato', 0.7805861234664917),\n",
       " ('cake', 0.7689308524131775),\n",
       " ('spicy', 0.7681053876876831),\n",
       " ('anise', 0.7667413949966431),\n",
       " ('sweets', 0.7644729614257812),\n",
       " ('jelly', 0.763335645198822)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar(\"sweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"../models/gensim_wikipedia_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
